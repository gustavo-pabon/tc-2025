{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c78c15da-fdc1-470d-896e-7fcf06ac7d0d",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\n",
    "    <img \n",
    "        src=\"./img/Microsoft-Logo.png\" \n",
    "        width=\"400\"/>\n",
    "</h1>\n",
    "<h1 align=\"center\">\n",
    "    <b>Practical Guide</b>\n",
    "</h1>\n",
    "<h4 align=\"center\">\n",
    "    for the creation of an AI Solution using an accelerator from the <a href=\"https://www.ds-toolkit.com/\">Data Science Toolkit</a>\n",
    "</h4>\n",
    "\n",
    "# What to expect\n",
    "\n",
    "* **Challenge 1:** *Create your own AI solution*\n",
    "* **Challenge 2:** *Getting answers from our new Copilot*\n",
    "* **Challenge 3:** *Evaluate the quality of the AI solution*\n",
    "\n",
    "# Challenge 1: *Create your own AI solution*\n",
    "\n",
    "Here we are going to create a RAG based Copilot to answer questions about 6 sustainability reports from Microsoft, Apple, Amazon, Google, Meta and Netflix from 2021 or 2022. The documents are part of the  [Mini Esg Bench Dataset](https://llamahub.ai/l/llama_datasets/Mini%20ESG%20Bench%20Dataset?from=llama_datasets).\n",
    "\n",
    "## Challenge 1 - Step 1:  *Let's import the libraries to be used in this notebook*.\n",
    "\n",
    "> This step will take around **30 to 90 seconds** to complete. It is going to be done in a quiet mode, so only errors will be displayed (if they occur). If you want to see what is going to be installed check the [requirements.txt](./requirements.txt) file.\n",
    "\n",
    "In summary two main tools will be installed and used in this notebook:\n",
    "\n",
    "* **Llama Index**. Which will be used to download the dataset and to create the Semantic Index.\n",
    "  > It is also possible to use **Azure AI Search** to create the semantic index. However, since it is going to be a small index, to simplify its creation in-memory we are going to use Llama Index.\n",
    "* **RAGAS**. Ragas will be used to calculate the metrics for the Copilot that we are going to create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff22fcb7-9752-4a1b-b168-c2e46758e978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# To create the RAG based copilot\n",
    "from llama_index.core.llama_dataset import LabelledRagDataset\n",
    "from llama_index.core.readers import SimpleDirectoryReader\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from ragas.metrics import (\n",
    "    Faithfulness,\n",
    "    ContextPrecision,\n",
    "    ContextRecall\n",
    ")\n",
    "\n",
    "# To calculate the Generative AI quality metrics\n",
    "from ragas.llms import LlamaIndexLLMWrapper\n",
    "from ragas.embeddings import LlamaIndexEmbeddingsWrapper\n",
    "from ragas.dataset_schema import SingleTurnSample, EvaluationDataset\n",
    "from ragas.evaluation import evaluate\n",
    "from ragas.run_config import RunConfig\n",
    "\n",
    "# To create a simple PDF visualization tool\n",
    "import pymupdf\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "# For formatting purposes\n",
    "import textwrap\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4bf4c3-9881-4fd0-a1e7-a81c0a5531f5",
   "metadata": {},
   "source": [
    "## Challenge 1 - Step 2: *Let's load the documents and test questions*\n",
    "\n",
    "> This step takes around **1 minute** to complete.\n",
    "\n",
    "The following code loads and prepares data from different sources (a JSON file and a directory of files) for further use:\n",
    "1. The first line creates an instance of LabelledRagDataset by loading data from a JSON file `rag_dataset.json`. The `from_json` method is a class method that reads the JSON file, parses its content, and initializes the `LabelledRagDataset` object with the parsed data. This method ensures that the data is correctly formatted and validated before being used.\n",
    "2. The second line initializes an instance of `SimpleDirectoryReader` with the directory path `source_files`. The `SimpleDirectoryReader` class is designed to read files from a specified directory. The `load_data` method is then called on this instance to load the documents from the directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4086796a-89cd-47dc-a54c-aca6d095e654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 6/6 [00:57<00:00,  9.51s/file]\n"
     ]
    }
   ],
   "source": [
    "# explain the code below\n",
    "\n",
    "rag_dataset = LabelledRagDataset.from_json(\"./data/rag_dataset.json\")\n",
    "documents = SimpleDirectoryReader(input_dir=\"./data/source_files/\").load_data(\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09182d0c-5b3c-4d9b-a7c6-ac6a04790b32",
   "metadata": {},
   "source": [
    "### Tool to visualize the reports just downloaded\n",
    "\n",
    "The following cell creates a tool to visualize the PDF files we just downloaded. If you want to take a look at the downloaded reports manually, just navigate to the `data/source_files` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b73ae8-1733-4654-b9fe-f64a366d4065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64cbfbb0499244eda5666267bf328616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Select a PDF:', options=('./data/source_files\\\\2022 Microsoft Environment…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_source_path = \"./data/source_files\"\n",
    "\n",
    "# List of pdf files just downloaded\n",
    "pdf_files = [os.path.join(data_source_path, file_name) for file_name in os.listdir(data_source_path)]\n",
    "\n",
    "# Function to render a specific page of a PDF\n",
    "def render_pdf_page(pdf_path, page_number=0):\n",
    "    # Open the PDF file\n",
    "    pdf_document = pymupdf.open(pdf_path)\n",
    "    \n",
    "    # Ensure the page number is valid\n",
    "    if page_number < 0 or page_number >= len(pdf_document):\n",
    "        raise ValueError(\"Invalid page number.\")\n",
    "    \n",
    "    # Get the page and render it as an image\n",
    "    page = pdf_document[page_number]\n",
    "    pix = page.get_pixmap()\n",
    "    pdf_document.close()\n",
    "    \n",
    "    # Display the image using Matplotlib\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(pix.pil_image())\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Function to update the displayed page\n",
    "def update_page(step):\n",
    "    global current_page\n",
    "    pdf_document = pymupdf.open(dropdown.value)\n",
    "    total_pages = len(pdf_document)\n",
    "    pdf_document.close()\n",
    "    \n",
    "    # Update the current page index\n",
    "    current_page += step\n",
    "    if current_page < 0:\n",
    "        current_page = 0\n",
    "    elif current_page >= total_pages:\n",
    "        current_page = total_pages - 1\n",
    "    \n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        render_pdf_page(dropdown.value, current_page)\n",
    "\n",
    "# Function to reset the viewer when a new PDF is selected\n",
    "def reset_viewer(change):\n",
    "    global current_page\n",
    "    current_page = 0  # Reset to the first page\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        render_pdf_page(dropdown.value, current_page)\n",
    "\n",
    "# Create widgets\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=pdf_files,\n",
    "    description=\"Select a PDF:\",\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "prev_button = widgets.Button(description=\"Previous Page\")\n",
    "next_button = widgets.Button(description=\"Next Page\")\n",
    "output = widgets.Output()\n",
    "\n",
    "# Attach event listeners\n",
    "prev_button.on_click(lambda _: update_page(-1))\n",
    "next_button.on_click(lambda _: update_page(1))\n",
    "dropdown.observe(reset_viewer, names=\"value\")\n",
    "\n",
    "# Initial display\n",
    "reset_viewer(None)\n",
    "\n",
    "# Display widgets and output\n",
    "display(widgets.VBox([dropdown, widgets.HBox([prev_button, next_button]), output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27593f21-4b06-4f54-bf8e-b7c7df1fa46c",
   "metadata": {},
   "source": [
    "## Challenge 1 - Step 3: *Let's create the semantic index*\n",
    "\n",
    "> This process can take up to **15 seconds** to complete\n",
    "\n",
    "A semantic index is a method used to organize and retrieve information based on the meaning and context of the content rather than just keywords. Unlike traditional keyword-based search systems, a semantic index understands the relationships between concepts and terms within the data, allowing for more accurate and relevant search results. In this context (i.e., ML and NLP), a semantic index leverages embeddings, which are numerical representations of words, phrases, or documents in a high-dimensional space. These embeddings capture the semantic meaning of the content, enabling the system to identify similar or related items even if they do not share exact keywords. The following code creates a semantic index using Azure OpenAI embeddings. The embedding model is used to generate embeddings for the documents, which are then indexed using `VectorStoreIndex` from `llamaIndex`. This process allows for efficient and meaningful retrieval of information based on the semantic content of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7734c8e-3326-4a82-b1a6-7e5db3db1f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4746d29b57f4ec78d0736a7b4d7639f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/455 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc00a71007a9448ab1fa658547c315f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.23 s\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create the embedding model\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model='text-embedding-3-small', # Update with the embeddings deployment name\n",
    "    api_key=os.environ['OPENAI_API_KEY'],\n",
    "    api_version=os.environ['OPENAI_API_VERSION'],\n",
    "    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT']\n",
    ")\n",
    "\n",
    "# Pass the embedding model to llamaIndex\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "# Create the actual index\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=documents,\n",
    "    show_progress=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdf8b61-3d12-4e5d-8b9e-e852897b9585",
   "metadata": {},
   "source": [
    "## Challenge 1 - Step 4: *Let's create the copilot*\n",
    "\n",
    "A large language model (LLM) is a type of machine learning model designed for natural language processing tasks such as language generation, translation, summarization, and more. These models are characterized by their vast number of parameters, which enable them to understand and generate human-like text with high accuracy and fluency. LLMs are trained on extensive datasets using self-supervised learning, allowing them to acquire a deep understanding of language, including syntax, semantics, and contextual relationships.\n",
    "\n",
    "Here we are creating an instance of a large language model using Azure OpenAI. The model, identified as `gpt-4o`, is configured with specific parameters such as `engine`, `model`, `temperature`, and API credentials. This setup allows the model to generate text based on the input it receives, making it a powerful tool for various natural language processing tasks.\n",
    "\n",
    "The following code creates and configures the large language model using Azure OpenAI, and integrates it with the previously created semantic index to enable efficient and meaningful query processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb8b041-6ef4-40be-a2be-70828a2865a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Large Language Model\n",
    "llm = AzureOpenAI(\n",
    "    engine=\"gpt-4o\", # Update with the language model deployment name \n",
    "    model=\"gpt-4o\", # Update with the language model name\n",
    "    temperature=0.0,\n",
    "    api_key=os.environ['OPENAI_API_KEY'],\n",
    "    api_version=os.environ['OPENAI_API_VERSION'],\n",
    "    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT']\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "\n",
    "query_engine = index.as_query_engine() # this is the copilot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91738a2c-4eae-4734-9748-5dff74d8b87d",
   "metadata": {},
   "source": [
    "### Let's play with the copilot just created\n",
    "\n",
    "In the test dataset, we have not only downloaded the source data (PDFs), but also 50 examples of questions/answer pairs to use with our Copilot. The following are some examples of the questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c2aafd0-1680-4871-801e-33be32930ddd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "* Can you provide for me the three highlights for the GHG emissions section of the Advancing Carbon-Free Energy Performance Highlights?\n",
       "* What percentage of waste from Google's offices globally were diverted away from landfills in 2021?\n",
       "* Can you present me with the performance highlights for Empowering Users With Technology?\n",
       "* What was the listed key achievement regarding sustainbility and climate change for Google in 2077?\n",
       "* Did Google reach its intended Waste target under the Building Better Devices and Services Initiative in 2021?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_samples = 5\n",
    "\n",
    "# Load some questions as example\n",
    "samples = rag_dataset.to_pandas().loc[:num_samples-1, 'query'].values\n",
    "\n",
    "display(Markdown(\"\\n\".join([ \"* \" + sample for sample in samples])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa5218b-6e99-49fb-b17e-67cb54a6b707",
   "metadata": {},
   "source": [
    "The following is a simple tool that allows to ask questions to the new copilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8416fd98-37ef-41ba-88c2-c665c210b264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5e79622ec64b17ac6df10496e27db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='You:', placeholder='Type your message here', style=TextStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to get a response\n",
    "def get_response(user_input):\n",
    "    return query_engine.query(user_input).response\n",
    "\n",
    "# Interactive chatbot function\n",
    "def chatbot():\n",
    "    output = widgets.Output(layout={'border': '1px solid black', 'height': '200px', 'overflow_y': 'scroll', 'white-space': 'pre-wrap'})\n",
    "    # output = widgets.Output(layout={})\n",
    "    text_box = widgets.Text(\n",
    "        placeholder=\"Type your message here\",\n",
    "        description=\"You:\",\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    submit_button = widgets.Button(description=\"Send\")\n",
    "    \n",
    "    def format_bot_response(bot_response, width=80):\n",
    "        # Wrap the response text at the specified width\n",
    "        formatted_response = \"\\n\".join(textwrap.wrap(bot_response, width))\n",
    "        return formatted_response\n",
    "\n",
    "    # Function to handle submission\n",
    "    def on_submit(_):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            user_message = text_box.value\n",
    "            if user_message.strip():  # Process non-empty input\n",
    "                bot_response = get_response(user_message)\n",
    "                display(Markdown(f\"You: {user_message}\"))\n",
    "                display(Markdown(f\"ESG Bot: {format_bot_response(bot_response, 100)}\"))\n",
    "            text_box.value = \"\"  # Clear the text box after submission\n",
    "    \n",
    "    # Link submission to pressing Enter in the text box\n",
    "    def on_enter(change):\n",
    "        if change[\"name\"] == \"value\" and change[\"new\"] == \"\":\n",
    "            on_submit(None)\n",
    "    \n",
    "    # Attach event handlers\n",
    "    text_box.observe(on_enter, names=\"value\")\n",
    "    submit_button.on_click(on_submit)\n",
    "    \n",
    "    display(widgets.VBox([text_box, submit_button, output]))\n",
    "\n",
    "# Run the chatbot\n",
    "chatbot()\n",
    "\n",
    "# Example question: What is Microsoft's most important contribution to the environment? → this is a question outside the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e495d817-9786-48e0-bbbf-84b1c899a71b",
   "metadata": {},
   "source": [
    "# Challenge 2: *Getting answers from our new Copilot*\n",
    "\n",
    "## Challenge 2 - Step 1: *Let's take a look at the test dataset*\n",
    "\n",
    "First, let's see an example from the test dataset that we downloaded together with the PDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e193ef78-b09b-4e60-acc3-851ff7b69859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### This is one instance in the dataset:\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**query:**\n",
       "\n",
       "Can you provide for me the three highlights for the GHG emissions section of the Advancing Carbon-Free Energy Performance Highlights?\n",
       "\n",
       "**reference_contexts:**\n",
       "\n",
       "* GHG emissions\n",
       "65%\n",
       "cumulative GHG\n",
       "emissions reduction\n",
       "From 2011 to 2021, our renewable energy purchasing resulted in a cumulative 65% reduction in our Scope 1 and Scope 2 emissions, as compared with a business-as-usual scenario in which we didn’t procure renewable energy via PPAs.\n",
       "81%\n",
       "decrease\n",
       "in carbon intensity\n",
       "From 2011 to 2021, our carbon intensity per unit of revenue\n",
       "decreased by 81%.\n",
       "15 years\n",
       "of carbon neutrality\n",
       "Google has been carbon neutral\n",
       "for our operations since 2007. Because of our purchases\n",
       "of renewable energy and\n",
       "procurement of high-quality\n",
       "carbon credits, we have compensated for all our\n",
       "operational GHG emissions.\n",
       "\n",
       "\n",
       "**reference_answer:**\n",
       "\n",
       "Sure, they are: \n",
       "1. 65% cumulative GHG emissions reduction\n",
       "2. 81% decrease in carbon intensity\n",
       "3. 15 years of carbon neutrality\n",
       "\n",
       "**reference_answer_by:**\n",
       "\n",
       "human\n",
       "\n",
       "**query_by:**\n",
       "\n",
       "human"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "instance_idx = 0\n",
    "\n",
    "def create_instance_md(k, v):\n",
    "    md_str = f\"**{k}:**\\n\\n\"\n",
    "    if k == \"reference_contexts\":\n",
    "        return md_str + \"\\n\".join([f\"* {c}\\n\" for c in v])\n",
    "    return md_str + f\"{v}\"\n",
    "\n",
    "display(Markdown(\"### This is one instance in the dataset:\\n\\n\"))\n",
    "display(Markdown(\"\\n\\n\".join([create_instance_md(k, v) for k,v in rag_dataset.to_pandas().iloc[instance_idx].items()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4765af1-d5b2-4427-8981-62837b41c149",
   "metadata": {},
   "source": [
    "### The dataset\n",
    "In total, the test dataset has 50 instances like the one detailed above, Let's take a look at some of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4de5ace0-0a60-4123-aabd-6f3cfb47a4eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_answer_by</th>\n",
       "      <th>query_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you provide for me the three highlights fo...</td>\n",
       "      <td>[GHG emissions\\n65%\\ncumulative GHG\\nemissions...</td>\n",
       "      <td>Sure, they are: \\n1. 65% cumulative GHG emissi...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What percentage of waste from Google's offices...</td>\n",
       "      <td>[64%\\nlandfill diversion\\nIn 2021, we reached ...</td>\n",
       "      <td>Sixty-four percent.</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you present me with the performance highli...</td>\n",
       "      <td>[EMPOWERING USERS WITH TECHNOLOGY\\nProducts\\nT...</td>\n",
       "      <td>Sure! The Performance Highlights for Empowerin...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What was the listed key achievement regarding ...</td>\n",
       "      <td>[We’ve been a leader on sustainability and cli...</td>\n",
       "      <td>In 2017, Google became the first major company...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did Google reach its intended Waste target und...</td>\n",
       "      <td>[Target: Achieve UL 2799 Zero Waste to Landfil...</td>\n",
       "      <td>No, this target has not been met in 2021. Howe...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How many EV charging locations were there on G...</td>\n",
       "      <td>[200,000\\nEV charging locations\\non Google Map...</td>\n",
       "      <td>200000</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>On what page of the report can I find the perf...</td>\n",
       "      <td>[EMPOWERING USERS WITH TECHNOLOGY\\nProducts\\nT...</td>\n",
       "      <td>The performance highlights for Empowering User...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Can you please provide for me the glossary of ...</td>\n",
       "      <td>[Glossary\\nCFE: carbon-free energyCO2e: carbon...</td>\n",
       "      <td>Sure, here is the glossary:\\nGlossary\\nCFE: ca...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>On what page can I find details about Amazons ...</td>\n",
       "      <td>[Contents\\nIntroduction\\n2 About Amazon\\n3 Ope...</td>\n",
       "      <td>You can find information on driving climate so...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>For the listed Renewable Energy goals, by when...</td>\n",
       "      <td>[Renewable Energy\\nGoal: Power our operations ...</td>\n",
       "      <td>Amazon set the goal of becoming powered by 100...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Can you provide for me the three highlights fo...   \n",
       "1  What percentage of waste from Google's offices...   \n",
       "2  Can you present me with the performance highli...   \n",
       "3  What was the listed key achievement regarding ...   \n",
       "4  Did Google reach its intended Waste target und...   \n",
       "5  How many EV charging locations were there on G...   \n",
       "6  On what page of the report can I find the perf...   \n",
       "7  Can you please provide for me the glossary of ...   \n",
       "8  On what page can I find details about Amazons ...   \n",
       "9  For the listed Renewable Energy goals, by when...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [GHG emissions\\n65%\\ncumulative GHG\\nemissions...   \n",
       "1  [64%\\nlandfill diversion\\nIn 2021, we reached ...   \n",
       "2  [EMPOWERING USERS WITH TECHNOLOGY\\nProducts\\nT...   \n",
       "3  [We’ve been a leader on sustainability and cli...   \n",
       "4  [Target: Achieve UL 2799 Zero Waste to Landfil...   \n",
       "5  [200,000\\nEV charging locations\\non Google Map...   \n",
       "6  [EMPOWERING USERS WITH TECHNOLOGY\\nProducts\\nT...   \n",
       "7  [Glossary\\nCFE: carbon-free energyCO2e: carbon...   \n",
       "8  [Contents\\nIntroduction\\n2 About Amazon\\n3 Ope...   \n",
       "9  [Renewable Energy\\nGoal: Power our operations ...   \n",
       "\n",
       "                                    reference_answer reference_answer_by  \\\n",
       "0  Sure, they are: \\n1. 65% cumulative GHG emissi...               human   \n",
       "1                                Sixty-four percent.               human   \n",
       "2  Sure! The Performance Highlights for Empowerin...               human   \n",
       "3  In 2017, Google became the first major company...               human   \n",
       "4  No, this target has not been met in 2021. Howe...               human   \n",
       "5                                             200000               human   \n",
       "6  The performance highlights for Empowering User...               human   \n",
       "7  Sure, here is the glossary:\\nGlossary\\nCFE: ca...               human   \n",
       "8  You can find information on driving climate so...               human   \n",
       "9  Amazon set the goal of becoming powered by 100...               human   \n",
       "\n",
       "  query_by  \n",
       "0    human  \n",
       "1    human  \n",
       "2    human  \n",
       "3    human  \n",
       "4    human  \n",
       "5    human  \n",
       "6    human  \n",
       "7    human  \n",
       "8    human  \n",
       "9    human  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_dataset.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4151b90f-d7d3-43a7-9ac2-7910013e61fb",
   "metadata": {},
   "source": [
    "## Challenge 2 - Step 2: *Let's calculate the responses*\n",
    "\n",
    "Now, let's have the model we created **provide answers to the questions** in the dataset. Also, to be able to calculate the quality metrics, we need to keep the **contexts retrieved**.  The retrieved contexts are the chunks of data retrieved from the semantic index to be used to answer the question.\n",
    "\n",
    "> This process could take hours depending on the thoughtput of the LLM used. Just to keep the practical guide in a reasonable time, let's calculate the **responses** and **retrieved contexts** for a small sample of questions. For future steps, we will provide the full dataset with already pre-calculated answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e15fa1e1-443b-4584-8633-4d848d461f3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_answer_by</th>\n",
       "      <th>query_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you provide for me the three highlights fo...</td>\n",
       "      <td>[GHG emissions\\n65%\\ncumulative GHG\\nemissions...</td>\n",
       "      <td>Sure, they are: \\n1. 65% cumulative GHG emissi...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What percentage of waste from Google's offices...</td>\n",
       "      <td>[64%\\nlandfill diversion\\nIn 2021, we reached ...</td>\n",
       "      <td>Sixty-four percent.</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you present me with the performance highli...</td>\n",
       "      <td>[EMPOWERING USERS WITH TECHNOLOGY\\nProducts\\nT...</td>\n",
       "      <td>Sure! The Performance Highlights for Empowerin...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What was the listed key achievement regarding ...</td>\n",
       "      <td>[We’ve been a leader on sustainability and cli...</td>\n",
       "      <td>In 2017, Google became the first major company...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did Google reach its intended Waste target und...</td>\n",
       "      <td>[Target: Achieve UL 2799 Zero Waste to Landfil...</td>\n",
       "      <td>No, this target has not been met in 2021. Howe...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Can you provide for me the three highlights fo...   \n",
       "1  What percentage of waste from Google's offices...   \n",
       "2  Can you present me with the performance highli...   \n",
       "3  What was the listed key achievement regarding ...   \n",
       "4  Did Google reach its intended Waste target und...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [GHG emissions\\n65%\\ncumulative GHG\\nemissions...   \n",
       "1  [64%\\nlandfill diversion\\nIn 2021, we reached ...   \n",
       "2  [EMPOWERING USERS WITH TECHNOLOGY\\nProducts\\nT...   \n",
       "3  [We’ve been a leader on sustainability and cli...   \n",
       "4  [Target: Achieve UL 2799 Zero Waste to Landfil...   \n",
       "\n",
       "                                    reference_answer reference_answer_by  \\\n",
       "0  Sure, they are: \\n1. 65% cumulative GHG emissi...               human   \n",
       "1                                Sixty-four percent.               human   \n",
       "2  Sure! The Performance Highlights for Empowerin...               human   \n",
       "3  In 2017, Google became the first major company...               human   \n",
       "4  No, this target has not been met in 2021. Howe...               human   \n",
       "\n",
       "  query_by  \n",
       "0    human  \n",
       "1    human  \n",
       "2    human  \n",
       "3    human  \n",
       "4    human  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a subset sample to test\n",
    "sample_size = 5\n",
    "sub_dataset = LabelledRagDataset(examples=rag_dataset.examples[:sample_size])\n",
    "sub_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18721527-37e9-468f-997f-2e69380571fc",
   "metadata": {},
   "source": [
    "Now, let's calculate the responses for the **subset** (this should take ~1m):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25db0141-6337-428e-8ced-b30bdcc19982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:07<00:00,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 391 ms\n",
      "Wall time: 7.36 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = sub_dataset.make_predictions_with(\n",
    "    predictor = query_engine,\n",
    "    show_progress = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f9e2f4-3cbd-41ff-8e49-c07bdce14b81",
   "metadata": {},
   "source": [
    "Let's look at the results:\n",
    "\n",
    "> Here, since we are already preparing the data for the next challenge the column names changed:\n",
    "> * `user_input` is the same `query` in the previous format.\n",
    "> * `retrieved_contexts` is a list that includes the chucks of data used by our copilot to answer the question.\n",
    "> * `response` is the `response` to the question created by our new copilot.\n",
    "> * `reference` is the `reference answer` from our previous format and refers to the expected answer created by a human."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c70fa284-6975-4679-8553-c7da5d006f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you provide for me the three highlights fo...</td>\n",
       "      <td>[31. In 2018, to align with industry best prac...</td>\n",
       "      <td>The three highlights for the GHG emissions sec...</td>\n",
       "      <td>Sure, they are: \\n1. 65% cumulative GHG emissi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What percentage of waste from Google's offices...</td>\n",
       "      <td>[Performance highlights\\nThe following section...</td>\n",
       "      <td>The percentage of waste diverted away from lan...</td>\n",
       "      <td>Sixty-four percent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you present me with the performance highli...</td>\n",
       "      <td>[Education\\nFor more than 40 years, we’ve work...</td>\n",
       "      <td>Apple has focused on empowering users with tec...</td>\n",
       "      <td>Sure! The Performance Highlights for Empowerin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What was the listed key achievement regarding ...</td>\n",
       "      <td>[Our approach\\nWe believe that every business ...</td>\n",
       "      <td>There is no listed key achievement for Google ...</td>\n",
       "      <td>In 2017, Google became the first major company...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did Google reach its intended Waste target und...</td>\n",
       "      <td>[BUILDING BETTER DEVICES AND SERVICES\\nTarget ...</td>\n",
       "      <td>Yes, in 2021, Google achieved the UL 2799 Zero...</td>\n",
       "      <td>No, this target has not been met in 2021. Howe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  Can you provide for me the three highlights fo...   \n",
       "1  What percentage of waste from Google's offices...   \n",
       "2  Can you present me with the performance highli...   \n",
       "3  What was the listed key achievement regarding ...   \n",
       "4  Did Google reach its intended Waste target und...   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [31. In 2018, to align with industry best prac...   \n",
       "1  [Performance highlights\\nThe following section...   \n",
       "2  [Education\\nFor more than 40 years, we’ve work...   \n",
       "3  [Our approach\\nWe believe that every business ...   \n",
       "4  [BUILDING BETTER DEVICES AND SERVICES\\nTarget ...   \n",
       "\n",
       "                                            response  \\\n",
       "0  The three highlights for the GHG emissions sec...   \n",
       "1  The percentage of waste diverted away from lan...   \n",
       "2  Apple has focused on empowering users with tec...   \n",
       "3  There is no listed key achievement for Google ...   \n",
       "4  Yes, in 2021, Google achieved the UL 2799 Zero...   \n",
       "\n",
       "                                           reference  \n",
       "0  Sure, they are: \\n1. 65% cumulative GHG emissi...  \n",
       "1                                Sixty-four percent.  \n",
       "2  Sure! The Performance Highlights for Empowerin...  \n",
       "3  In 2017, Google became the first major company...  \n",
       "4  No, this target has not been met in 2021. Howe...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_samples = []\n",
    "\n",
    "for idx in range(len(sub_dataset.examples)):\n",
    "    list_of_samples.append(\n",
    "        SingleTurnSample (\n",
    "            user_input = sub_dataset.examples[idx].query,\n",
    "            reference = sub_dataset.examples[idx].reference_answer,\n",
    "            response = predictions.predictions[idx].response,\n",
    "            retrieved_contexts = predictions.predictions[idx].contexts\n",
    "        )\n",
    "    )\n",
    "\n",
    "ragas_evaluation_dataset = EvaluationDataset(list_of_samples)\n",
    "ragas_evaluation_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce6d120-e5e7-47d4-88f5-114ff658a067",
   "metadata": {},
   "source": [
    "# Challenge 3: *Evaluate the quality of our new copilot*\n",
    "\n",
    "Evaluating Generative AI (GenAI) solutions, especially those using Retrieval-Augmented Generation (RAG) frameworks, involves several key steps to ensure the quality and effectiveness of the generated outputs. \n",
    "\n",
    "GenAI solutions are evaluated using various metrics to measure the quality of the responses generated by the AI models. Libraries like RAGAS or promptflow are instrumental in this process. They help assess the solution's performance using metrics such as faithfulness, groundedness, context precision, and context recall1. These metrics provide insights into how accurate, relevant, and contextually appropriate the AI-generated responses are.\n",
    "\n",
    "The evaluation process typically includes:\n",
    "\n",
    "* **Model Selection and Building:** Choosing the right model and developing the GenAI application using iterative development practices and advanced prompt engineering techniques.\n",
    "* **Quality Metrics:** Using metrics like faithfulness (accuracy and truthfulness), groundedness (relevance to the input context), context precision (alignment with the provided context), and context recall (inclusion of relevant information from the input context).\n",
    "* **Explainability:** Adding explainability to these metrics to understand why certain responses are rated higher or lower. This helps in debugging and improving the overall solution.\n",
    "* **User Feedback:** Collecting feedback from users to identify unexpected issues and improve the user experience.\n",
    "\n",
    "For this demonstration, we use RAGAS, a specialized evaluation framework designed to assess the performance of RAG systems. It provides a structured approach to evaluate the effectiveness of RAG implementations by leveraging advanced Large Language Models (LLMs) as judges. \n",
    "\n",
    "## Challenge 3 - Step 1: *Initialize the LLM and Embedding models*\n",
    "\n",
    "The first step is to initialize the LLM and Embedding models to be used to calculate the GenAI metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95d20855-309e-4e36-a07c-9ea551d41a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_llm = LlamaIndexLLMWrapper(llm)\n",
    "evaluator_embeddings = LlamaIndexEmbeddingsWrapper(embed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e027f6ef-80c0-495e-8096-dfb48c6d3b47",
   "metadata": {},
   "source": [
    "## Challenge 3 - Step 2: *Calculate the GenAI metrics*\n",
    "\n",
    "The process to calculate the GenAI metrics for all the questions in the test dataset could take hours depending on the throughtput of the LLM and the Embedding model used. To keep the time of this guide we are going to calculate only 3 metrics for the sub dataset created before:\n",
    "\n",
    "* **Context prescision:** Measures how much of the generated output is relevant and aligns with the context provided in the input.\n",
    "* **Context recall:** Measures how much of the relevant information in the input context is included in the output.\n",
    "* **Faithfulness:** Measures how accurate and truthful the generated output is in relation to the input context and factual correctness. Faithfulness is about avoiding \"hallucinations\" (made-up or false information).\n",
    "\n",
    "\n",
    "> This process can take up to **25 seconds** to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37fe2de4-576b-4d3b-bf26-1885a4f91411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf996f08e9cf449088b51e8055e22905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d707dca80bf4b1c8bd7fa16c100614f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch 1/3:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 484 ms\n",
      "Wall time: 24.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "metrics = [\n",
    "    Faithfulness(llm=evaluator_llm),\n",
    "    ContextPrecision(llm=evaluator_llm),\n",
    "    ContextRecall(llm=evaluator_llm)\n",
    "]\n",
    "ragas_evaluation_result = evaluate(\n",
    "    dataset=ragas_evaluation_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embeddings,\n",
    "    run_config=RunConfig(timeout=1800, max_wait=180, max_retries=20),\n",
    "    show_progress=True,\n",
    "    batch_size=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecec49e5-c34a-405d-8120-48bf9293329f",
   "metadata": {},
   "source": [
    "The following are the results of the calculation of the GenAI metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f35bb08-587e-4c7e-a8a6-5d4526d9fdbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you provide for me the three highlights fo...</td>\n",
       "      <td>[31. In 2018, to align with industry best prac...</td>\n",
       "      <td>The three highlights for the GHG emissions sec...</td>\n",
       "      <td>Sure, they are: \\n1. 65% cumulative GHG emissi...</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What percentage of waste from Google's offices...</td>\n",
       "      <td>[Performance highlights\\nThe following section...</td>\n",
       "      <td>The percentage of waste diverted away from lan...</td>\n",
       "      <td>Sixty-four percent.</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you present me with the performance highli...</td>\n",
       "      <td>[Education\\nFor more than 40 years, we’ve work...</td>\n",
       "      <td>Apple has focused on empowering users with tec...</td>\n",
       "      <td>Sure! The Performance Highlights for Empowerin...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What was the listed key achievement regarding ...</td>\n",
       "      <td>[Our approach\\nWe believe that every business ...</td>\n",
       "      <td>There is no listed key achievement for Google ...</td>\n",
       "      <td>In 2017, Google became the first major company...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did Google reach its intended Waste target und...</td>\n",
       "      <td>[BUILDING BETTER DEVICES AND SERVICES\\nTarget ...</td>\n",
       "      <td>Yes, in 2021, Google achieved the UL 2799 Zero...</td>\n",
       "      <td>No, this target has not been met in 2021. Howe...</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  Can you provide for me the three highlights fo...   \n",
       "1  What percentage of waste from Google's offices...   \n",
       "2  Can you present me with the performance highli...   \n",
       "3  What was the listed key achievement regarding ...   \n",
       "4  Did Google reach its intended Waste target und...   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [31. In 2018, to align with industry best prac...   \n",
       "1  [Performance highlights\\nThe following section...   \n",
       "2  [Education\\nFor more than 40 years, we’ve work...   \n",
       "3  [Our approach\\nWe believe that every business ...   \n",
       "4  [BUILDING BETTER DEVICES AND SERVICES\\nTarget ...   \n",
       "\n",
       "                                            response  \\\n",
       "0  The three highlights for the GHG emissions sec...   \n",
       "1  The percentage of waste diverted away from lan...   \n",
       "2  Apple has focused on empowering users with tec...   \n",
       "3  There is no listed key achievement for Google ...   \n",
       "4  Yes, in 2021, Google achieved the UL 2799 Zero...   \n",
       "\n",
       "                                           reference  faithfulness  \\\n",
       "0  Sure, they are: \\n1. 65% cumulative GHG emissi...         0.875   \n",
       "1                                Sixty-four percent.         1.000   \n",
       "2  Sure! The Performance Highlights for Empowerin...         1.000   \n",
       "3  In 2017, Google became the first major company...         1.000   \n",
       "4  No, this target has not been met in 2021. Howe...         0.500   \n",
       "\n",
       "   context_precision  context_recall  \n",
       "0                0.0             0.0  \n",
       "1                0.0             0.0  \n",
       "2                0.0             0.0  \n",
       "3                1.0             1.0  \n",
       "4                1.0             1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ragas_result = ragas_evaluation_result.to_pandas()\n",
    "df_ragas_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2cf0a4-06e5-4060-b983-dc993c5c3862",
   "metadata": {},
   "source": [
    "### Full dataset results\n",
    "\n",
    "Let's take a look at a table with the responses, retrieved contexts and metrics already pre-calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8824016-51b4-457a-ad37-3b840c6b3972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you provide for me the three highlights fo...</td>\n",
       "      <td>[31. In 2018, to align with industry best prac...</td>\n",
       "      <td>The three highlights for the GHG emissions sec...</td>\n",
       "      <td>Sure, they are: \\n1. 65% cumulative GHG emissi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What percentage of waste from Google's offices...</td>\n",
       "      <td>[Performance highlights\\nThe following section...</td>\n",
       "      <td>In 2021, 78% of waste from Google's global dat...</td>\n",
       "      <td>Sixty-four percent.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you present me with the performance highli...</td>\n",
       "      <td>[Education\\nFor more than 40 years, we’ve work...</td>\n",
       "      <td>The performance highlights for empowering user...</td>\n",
       "      <td>Sure! The Performance Highlights for Empowerin...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What was the listed key achievement regarding ...</td>\n",
       "      <td>[Our approach\\nWe believe that every business ...</td>\n",
       "      <td>There is no listed key achievement for Google ...</td>\n",
       "      <td>In 2017, Google became the first major company...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did Google reach its intended Waste target und...</td>\n",
       "      <td>[BUILDING BETTER DEVICES AND SERVICES\\nTarget ...</td>\n",
       "      <td>Yes, in 2021, Google achieved the UL 2799 Zero...</td>\n",
       "      <td>No, this target has not been met in 2021. Howe...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How many EV charging locations were there on G...</td>\n",
       "      <td>[This guidance does not recognize existing ren...</td>\n",
       "      <td>The provided context does not specify the numb...</td>\n",
       "      <td>200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>On what page of the report can I find the perf...</td>\n",
       "      <td>[Employee Recruitment, Inclusion and Performan...</td>\n",
       "      <td>The performance highlights for the Empowering ...</td>\n",
       "      <td>The performance highlights for Empowering User...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Can you please provide for me the glossary of ...</td>\n",
       "      <td>[GRI INDEX\\nGRI 304 - Biodiversity\\nGRI 103 Ma...</td>\n",
       "      <td>I'm unable to provide the glossary of the docu...</td>\n",
       "      <td>Sure, here is the glossary:\\nGlossary\\nCFE: ca...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>On what page can I find details about Amazons ...</td>\n",
       "      <td>[IntroductionSustainability\\nDriving Climate S...</td>\n",
       "      <td>You can find details about Amazon's climate so...</td>\n",
       "      <td>You can find information on driving climate so...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>For the listed Renewable Energy goals, by when...</td>\n",
       "      <td>[IntroductionSustainability\\nDriving Climate S...</td>\n",
       "      <td>Amazon intends to have all operations powered ...</td>\n",
       "      <td>Amazon set the goal of becoming powered by 100...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Can you provide the Actions taken by Amazon fo...</td>\n",
       "      <td>[IntroductionSustainability\\nDriving Climate S...</td>\n",
       "      <td>Amazon has taken several actions to achieve it...</td>\n",
       "      <td>Sure, here they are:\\nActions\\n90% Electricity...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What were Amazon's Carbon Intesity values in (...</td>\n",
       "      <td>[IntroductionSustainability\\nDriving Climate S...</td>\n",
       "      <td>Amazon's Carbon Intensity values in grams of C...</td>\n",
       "      <td>Sure, here they are:\\n2019: 122.8\\n2020: 102.7...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What were Amazon's Total Carbon Footprint (MMT...</td>\n",
       "      <td>[IntroductionSustainability\\nDriving Climate S...</td>\n",
       "      <td>Amazon's Total Carbon Footprint in million met...</td>\n",
       "      <td>Amazon's total footprint for the years 2019-20...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>On what page can of the report can I find info...</td>\n",
       "      <td>[Tackling Climate  \\nMisinformation\\n \\nClimat...</td>\n",
       "      <td>The report does not contain information about ...</td>\n",
       "      <td>On page 14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What household brands were featured in the in ...</td>\n",
       "      <td>[Customer Shopping Experience\\nWe have enabled...</td>\n",
       "      <td>The context does not provide information about...</td>\n",
       "      <td>Microsoft, jetBlue, Uber, Mercedez-Benz, Visa,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What percentage of corporate emissions since 2...</td>\n",
       "      <td>[IntroductionSustainability\\nDriving Climate S...</td>\n",
       "      <td>Since 2020, 100% of the electricity used in co...</td>\n",
       "      <td>100% since April 2020.</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>In Apple's comprehensive carbon footprint, wha...</td>\n",
       "      <td>[Gross emissions\\n   \\nAvoided emissions\\n  \\n...</td>\n",
       "      <td>The top two categories leading to the most avo...</td>\n",
       "      <td>The top two categories were: supplier clean en...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>By what percentage did Apple reduce plastic in...</td>\n",
       "      <td>[Across our business, we released eight \\nprod...</td>\n",
       "      <td>Apple reduced plastic in packaging by 75 perce...</td>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How many metric tons of waste were redirected ...</td>\n",
       "      <td>[Current\\nyear\\nBase\\nyear\\nTarget\\nDiversion ...</td>\n",
       "      <td>The provided context does not specify the amou...</td>\n",
       "      <td>More than 2 million metric tons of waste were ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>In 2021, how many hours were spent by staff ac...</td>\n",
       "      <td>[Growth and development\\nWe want everyone to f...</td>\n",
       "      <td>In 2021, team members spent more than 175,000 ...</td>\n",
       "      <td>175000 hours</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   Can you provide for me the three highlights fo...   \n",
       "1   What percentage of waste from Google's offices...   \n",
       "2   Can you present me with the performance highli...   \n",
       "3   What was the listed key achievement regarding ...   \n",
       "4   Did Google reach its intended Waste target und...   \n",
       "5   How many EV charging locations were there on G...   \n",
       "6   On what page of the report can I find the perf...   \n",
       "7   Can you please provide for me the glossary of ...   \n",
       "8   On what page can I find details about Amazons ...   \n",
       "9   For the listed Renewable Energy goals, by when...   \n",
       "10  Can you provide the Actions taken by Amazon fo...   \n",
       "11  What were Amazon's Carbon Intesity values in (...   \n",
       "12  What were Amazon's Total Carbon Footprint (MMT...   \n",
       "13  On what page can of the report can I find info...   \n",
       "14  What household brands were featured in the in ...   \n",
       "15  What percentage of corporate emissions since 2...   \n",
       "16  In Apple's comprehensive carbon footprint, wha...   \n",
       "17  By what percentage did Apple reduce plastic in...   \n",
       "18  How many metric tons of waste were redirected ...   \n",
       "19  In 2021, how many hours were spent by staff ac...   \n",
       "\n",
       "                                   retrieved_contexts  \\\n",
       "0   [31. In 2018, to align with industry best prac...   \n",
       "1   [Performance highlights\\nThe following section...   \n",
       "2   [Education\\nFor more than 40 years, we’ve work...   \n",
       "3   [Our approach\\nWe believe that every business ...   \n",
       "4   [BUILDING BETTER DEVICES AND SERVICES\\nTarget ...   \n",
       "5   [This guidance does not recognize existing ren...   \n",
       "6   [Employee Recruitment, Inclusion and Performan...   \n",
       "7   [GRI INDEX\\nGRI 304 - Biodiversity\\nGRI 103 Ma...   \n",
       "8   [IntroductionSustainability\\nDriving Climate S...   \n",
       "9   [IntroductionSustainability\\nDriving Climate S...   \n",
       "10  [IntroductionSustainability\\nDriving Climate S...   \n",
       "11  [IntroductionSustainability\\nDriving Climate S...   \n",
       "12  [IntroductionSustainability\\nDriving Climate S...   \n",
       "13  [Tackling Climate  \\nMisinformation\\n \\nClimat...   \n",
       "14  [Customer Shopping Experience\\nWe have enabled...   \n",
       "15  [IntroductionSustainability\\nDriving Climate S...   \n",
       "16  [Gross emissions\\n   \\nAvoided emissions\\n  \\n...   \n",
       "17  [Across our business, we released eight \\nprod...   \n",
       "18  [Current\\nyear\\nBase\\nyear\\nTarget\\nDiversion ...   \n",
       "19  [Growth and development\\nWe want everyone to f...   \n",
       "\n",
       "                                             response  \\\n",
       "0   The three highlights for the GHG emissions sec...   \n",
       "1   In 2021, 78% of waste from Google's global dat...   \n",
       "2   The performance highlights for empowering user...   \n",
       "3   There is no listed key achievement for Google ...   \n",
       "4   Yes, in 2021, Google achieved the UL 2799 Zero...   \n",
       "5   The provided context does not specify the numb...   \n",
       "6   The performance highlights for the Empowering ...   \n",
       "7   I'm unable to provide the glossary of the docu...   \n",
       "8   You can find details about Amazon's climate so...   \n",
       "9   Amazon intends to have all operations powered ...   \n",
       "10  Amazon has taken several actions to achieve it...   \n",
       "11  Amazon's Carbon Intensity values in grams of C...   \n",
       "12  Amazon's Total Carbon Footprint in million met...   \n",
       "13  The report does not contain information about ...   \n",
       "14  The context does not provide information about...   \n",
       "15  Since 2020, 100% of the electricity used in co...   \n",
       "16  The top two categories leading to the most avo...   \n",
       "17  Apple reduced plastic in packaging by 75 perce...   \n",
       "18  The provided context does not specify the amou...   \n",
       "19  In 2021, team members spent more than 175,000 ...   \n",
       "\n",
       "                                            reference  faithfulness  \\\n",
       "0   Sure, they are: \\n1. 65% cumulative GHG emissi...      1.000000   \n",
       "1                                 Sixty-four percent.      1.000000   \n",
       "2   Sure! The Performance Highlights for Empowerin...      1.000000   \n",
       "3   In 2017, Google became the first major company...      1.000000   \n",
       "4   No, this target has not been met in 2021. Howe...      0.666667   \n",
       "5                                              200000      1.000000   \n",
       "6   The performance highlights for Empowering User...      0.000000   \n",
       "7   Sure, here is the glossary:\\nGlossary\\nCFE: ca...      0.500000   \n",
       "8   You can find information on driving climate so...      0.000000   \n",
       "9   Amazon set the goal of becoming powered by 100...      1.000000   \n",
       "10  Sure, here they are:\\nActions\\n90% Electricity...      1.000000   \n",
       "11  Sure, here they are:\\n2019: 122.8\\n2020: 102.7...      1.000000   \n",
       "12  Amazon's total footprint for the years 2019-20...      1.000000   \n",
       "13                                         On page 14      1.000000   \n",
       "14  Microsoft, jetBlue, Uber, Mercedez-Benz, Visa,...      1.000000   \n",
       "15                             100% since April 2020.      0.333333   \n",
       "16  The top two categories were: supplier clean en...      1.000000   \n",
       "17                                                75%      1.000000   \n",
       "18  More than 2 million metric tons of waste were ...      1.000000   \n",
       "19                                       175000 hours      1.000000   \n",
       "\n",
       "    context_precision  context_recall  \n",
       "0                 0.0             0.0  \n",
       "1                 0.0             0.0  \n",
       "2                 0.0             0.0  \n",
       "3                 1.0             1.0  \n",
       "4                 1.0             1.0  \n",
       "5                 0.0             0.0  \n",
       "6                 0.0             0.0  \n",
       "7                 0.0             0.0  \n",
       "8                 0.0             0.0  \n",
       "9                 1.0             0.0  \n",
       "10                1.0             0.0  \n",
       "11                1.0             0.8  \n",
       "12                1.0             1.0  \n",
       "13                0.0             0.0  \n",
       "14                0.0             0.0  \n",
       "15                0.5             0.0  \n",
       "16                1.0             1.0  \n",
       "17                0.5             1.0  \n",
       "18                0.0             0.0  \n",
       "19                1.0             1.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_dataset = pd.read_json('./test-dataset.json', orient='records')\n",
    "df_test_dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e5b33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
